<!DOCTYPE html>




<html class="theme-next gemini" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="自动驾驶,自动驾驶仿真," />










<meta name="description" content="通过各种仿真模型和真实交通数据实现的虚拟交通是重建详细交通流的理想方法。各种应用程序都可以从虚拟交通中获益，包括但不限于视频游戏、虚拟现实、交通工程和自动驾驶。本文首先讨论了三种不同层次的交通模拟模型。然后，介绍了各种数据驱动的动画技术，包括现有的数据收集方法，以及模拟交通流的验证和评估。接下来讨论了交通模拟如何有益于自动驾驶车辆的训练和测试。最后，讨论了交通仿真与动画的研究现状，并提出了未来的研">
<meta name="keywords" content="自动驾驶,自动驾驶仿真">
<meta property="og:type" content="article">
<meta property="og:title" content="交通流仿真总结">
<meta property="og:url" content="http://iamwxy.com/交通流仿真总结.html">
<meta property="og:site_name" content="南浔遇雨">
<meta property="og:description" content="通过各种仿真模型和真实交通数据实现的虚拟交通是重建详细交通流的理想方法。各种应用程序都可以从虚拟交通中获益，包括但不限于视频游戏、虚拟现实、交通工程和自动驾驶。本文首先讨论了三种不同层次的交通模拟模型。然后，介绍了各种数据驱动的动画技术，包括现有的数据收集方法，以及模拟交通流的验证和评估。接下来讨论了交通模拟如何有益于自动驾驶车辆的训练和测试。最后，讨论了交通仿真与动画的研究现状，并提出了未来的研">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2020-02-14T11:08:36.082Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="交通流仿真总结">
<meta name="twitter:description" content="通过各种仿真模型和真实交通数据实现的虚拟交通是重建详细交通流的理想方法。各种应用程序都可以从虚拟交通中获益，包括但不限于视频游戏、虚拟现实、交通工程和自动驾驶。本文首先讨论了三种不同层次的交通模拟模型。然后，介绍了各种数据驱动的动画技术，包括现有的数据收集方法，以及模拟交通流的验证和评估。接下来讨论了交通模拟如何有益于自动驾驶车辆的训练和测试。最后，讨论了交通仿真与动画的研究现状，并提出了未来的研">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"right","display":"post","offset":24,"b2t":false,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://iamwxy.com/交通流仿真总结.html"/>





  <title>交通流仿真总结 | 南浔遇雨</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-right page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">南浔遇雨</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">博观而约取 厚积而薄发</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-envelope"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://iamwxy.com/交通流仿真总结.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="鲨鱼观海">
      <meta itemprop="description" content="生活随笔 高效学习 自动驾驶 数据分析 交叉领域 读书笔记 Coder&Engineer">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="南浔遇雨">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">交通流仿真总结</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">写于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-13T19:58:20+08:00">
                2020-02-13
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>通过各种仿真模型和真实交通数据实现的虚拟交通是重建详细交通流的理想方法。各种应用程序都可以从虚拟交通中获益，包括但不限于视频游戏、虚拟现实、交通工程和自动驾驶。本文首先讨论了三种不同层次的交通模拟模型。然后，介绍了各种数据驱动的动画技术，包括现有的数据收集方法，以及模拟交通流的验证和评估。接下来讨论了交通模拟如何有益于自动驾驶车辆的训练和测试。最后，讨论了交通仿真与动画的研究现状，并提出了未来的研究方向。</p>
<p>近年来，视觉交通越来越受到各种研究团体的关注，包括但不限于电脑游戏、城市可视化、城市规划和自动驾驶。在虚拟现实、游戏和动画中，城市场景是必不可少的，因此，不可避免的也会涉及大量的车辆。为了控制单个车辆的运动，一个简单的解决方案是使用关键帧（keyframe methods）方法。然而，使用关键帧方法模拟大规模交通场景中的交通拥堵、频繁的换道以及行人与车辆的交互，不仅需要动画师进行复杂的设计和重复的调整，而且生成的车辆运动很少符合物理规律。因此，有效地模拟大规模交通流已成为计算机图形学中一个越来越重要的课题。此外，由于OpenStreetMap、ESRI和谷歌Maps等道路网络可视化工具的普及，将实时交通流整合到虚拟道路网络中变得至关重要。<br>然而，实时获取车辆的实际轨迹并将其整合到虚拟应用中是非常困难的。这些趋势推动了数据驱动的交通模拟的研究工作。</p>
<p>除了上述在动画和可视化方面的应用外，交通仿真在交通研究中有着广泛的应用。VISSIM [PTV11]、TSIS [TSI18]、PARAMICS [PAR18]等交通仿真软件包是研究交通网络性能的有效工具。基于虚拟现实的驾驶培训项目通过生成真实的交通环境帮助新驾驶员提高驾驶技能[VRd18, LWX 18]。交通模拟还可以作为生成各种交通条件的有效工具，用于训练和测试自动驾驶车辆[SAMR18]</p>
<p>此外，日益增长的车辆流量和复杂的道路网络导致了许多与交通相关的问题，如交通堵塞、事故管理、信号控制和网络设计优化。这些问题很难用基于分析模型的传统工具解决[SHVDWVW16]。因此，人们尝试使用先进的计算技术对交通进行建模、仿真和可视化，以分析交通管理的交通条件[PBH12,WLY 13,WYL 14]，或帮助城市发展中的交通重建[GDGAVU14]</p>
<p>交通模拟的一个主要焦点是回答以下问题:给定道路网络、行为模型和初始车辆状态，交通将如何演变?交通流的建模与仿真有大量的数学描述，大致可以分为宏观模型[SWML10]、微观模型[SJ12]、细观模型[SWL11]。<br>宏观方法将车辆集合视为一个连续的流动，微观方法模拟每辆车在其周围车辆影响下的动态。相比之下，细观模型结合了微观和宏观模型的优点来模拟不同层次的交通细节。此外，道路网络的生成和表示也是交通仿真中的一个基本问题。</p>
<p>虽然前面提到的交通模型可以有效地捕获外观，但是得到的模拟结果通常不像真实的街道交通。随着先进的传感硬件和计算机视觉技术的发展，以视频、激光雷达和GPS传感器形式存在的经验交通流数据集越来越多。这种现象催生了数据驱动的交通动画技术。例子包括重建从现有道路交通流量传感器中获取的时空数据(SVDBLM11、WSL13 LWL17),从有限的样本轨迹合成新的交通流(CDR 18),和从交通监控数据集学习行为模式和独立特征以产生交通流[CSJ13 BMWD16】</p>
<p>尽管在交通模拟和动画方面取得了很大的进步，但是如何测量模拟交通的真实感一直没有得到充分的研究。此外，在基于模型的交通模拟和数据驱动的动画方法中，根据模拟交通和真实交通之间的相似性进行模型验证一直是一个关注的问题。为了解决这些问题，目前的方法包括使用主观的用户评价，并将客观的评价指标纳入度量[CDX 18]。</p>
<p>通过各种交通模拟和动画技术的虚拟交通也被应用到自动驾驶的训练中。自动驾驶有可能彻底改变我们的交通系统。然而在将这些自动化机器部署到真实世界之前，要在模拟环境中对它们进行训练。目前，自动驾驶车辆的性能测试通常使用一个具有预定义行为的单一干扰道路用户例如车辆、行人或自行车)在虚拟环境中进行[WEG 00,DRC 17,apo18]。通过在拥有丰富的不同道路使用者之间交互的模拟交通流中进行训练，自动驾驶汽车有可能获得在复杂的城市环境中处理复杂交通条件的能力。<br>此外，交通模拟和动画也可以受益于基于学习的运动规划和自动车辆决策算法。具体来说，随着采集到的驾驶数据集的增加，由此产生的准确的交通模拟可以在更准确的交通语义方面丰富自动驾驶车辆的运动规划和决策。</p>
<p>为了实现安全的自动驾驶，需要一个结合真实交通流和复杂交通条件的高保真驾驶模拟器。<br>这样的模拟器可以以高效和可重复的方式产生关键的培训环境。由于交通模拟在自动驾驶研究中变得越来越重要，在本次调查中，将特别从三个方面描述自动驾驶的最新发展:数据采集、运动规划和模拟测试。</p>
<p>第2节介绍了三种基于模型的交通仿真方法，并为道路网络的过程建模和几何表示提供了不同的代表方法。第3节介绍了基于不同数据获取方法的各种数据驱动的动画技术。第四部分探讨动画方法的验证与评价生成的虚拟交通。第5节介绍了最近在数据采集、运动规划和使用虚拟交通进行自动驾驶研究方面的努力。最后，第6节和第7节通过讨论现有研究的现状和我们对未来研究方向的看法来结束本次调查<br><a id="more"></a></p>
<h4 id="基于模型的交通流建模"><a href="#基于模型的交通流建模" class="headerlink" title="基于模型的交通流建模"></a>基于模型的交通流建模</h4><p>交通模拟的一个重要组成部分是在不同的细节水平上描绘车辆的运动。交通流建模与仿真的早期研究可以追溯到20世纪50年代，当时分别提出了宏观交通模型和微观交通模型的原型[Pip53, LW55]。经过多年的发展，交通仿真技术大致有三种类型<a href="如图3所示">VWKVLVH15,FSS18</a>，分别为宏观(2.1)、微观(2.2)和细观(mesoscopic)</p>
<p>交通流可以被看作是一种流:流中的车辆共享相似的目标和行为规则，与邻居交互，同时保持各自的驾驶特性。在计算机图形学中，群体仿真一直是一个重要的研究领域，它为集体行为和动力学的研究提供了支持[PAB08, ZCC 10]。人群模拟可以通过宏观方式以个体真实运动为代价对群体进行整体建模)[NGCL09]，也可以通过微观方式(将群体建模为个体运动的集合)[WLP16]</p>
<h5 id="宏观方法"><a href="#宏观方法" class="headerlink" title="宏观方法"></a>宏观方法</h5><p>宏观方法，也称为连续体方法，以较低的细节描述车辆的行为和相互作用:交通流由速度、流量、密度等连续体表示。宏观方法主要是为了效率而设计的大规模道路网络上的交通模拟，重点是再现用流量密度和交通流量等集体量测量的聚集行为。</p>
<p>早期的一阶宏观模型之一是由Lighthill和Whitham [LW55]和Richards [Ric56]开发的，称为LWR模型。他们的模型假设交通流量只依赖于描述流量-密度关系的交通密度。该模型基于一维可压缩气体动力学与单车道交通流演化的相似性，建立了交通流的非线性标量守恒律。从本质上讲，LWR模型以低分辨率的细节描述了大规模交通流的运动。它的局限性之一是，它不能模拟车辆在非平衡条件下的运动，比如走走停停的波浪。</p>
<p>随后，Payne [Pay71]和Whitham [Whi74]提出了连续二阶交通流模型，称为Payne-Whitham (PW)模型。一阶模型假设存在一个固定的平衡状态，二阶模型引入一个二阶微分方程来描述交通速度动态。作为一个限制，PW模型可以引入负速度，车辆动力学产生的信息可以比车辆速度更快，这意味着司机可以受到他们的后续车辆的影响。Aw和Rascle [AR00]和Zhang [Zha02]提出了对PW模型的修正，以消除其非物理行为。具体来说，Aw和Rascle [AR00]引入了一个压力项，以保证没有信息的传播速度超过汽车的速度。张[Zha02]同样提出了对PW模型动量方程的修正来处理向后传播的流量。得到的模型被称为Aw-Rascle-Zhang (ARZ)模型，该模型从[Ras02,GP06,LMHS07,MR07]开始被深入研究。Mammar等人[MLS09]表明，ARZ模型在数值上比LWR模型更适合真实世界的数据。</p>
<p>为了生成详细的交通流三维动画和可视化，Sewall等[SWML10提出了连续交通仿真模型，以生成大规模道路网络上真实的交通流。他们通过引入一种新的变道模型，并对每辆车使用离散表示，使单车道的ARZ模型适应于处理多车道交通。如图4所示，通过将每个车道离散成多个单元来模拟交通流。<br>为了更新每个单元的状态，使用有限体积法(FVM)进行空间离散化[LeV02]，并结合Riemann求解器对ARZ方程进行求解。为了对车道合并和变道行为进行建模，Sewall等人将连续动态与离散车辆信息相结合，将车辆表示为车辆粒子系统。这些粒子系统是由底层的连续流驱动的。</p>
<p>综上所述，宏观交通模型是模拟大规模交通的有效工具。然而，这些技术仅限于高速公路网络，因此不适合模拟街道交通，因为街道交通包含了汽车之间丰富的相互作用。此外，由于这些模型不模拟车辆的车道合并行为，因此无法处理换道过程中的密度传递。</p>
<h5 id="微观方法"><a href="#微观方法" class="headerlink" title="微观方法"></a>微观方法</h5><p>微观模型在高水平的细节上产生车辆运动:每辆车都被视为一个离散的代理，满足一定的控制规则。<br>针对特定的城市交通模拟，已经开发了大量的微观模型，这是因为它们可以灵活地建模代理的异构行为、不同的道路拓扑以及周围车辆之间的交互。</p>
<p>早期的微观模型包括元胞自动机模型[NS92]和汽车跟随模型[Pip53, HG63]。元胞自动机模型中车辆的运动由预先指定的时间、空间和状态变量中的演化规则来描述。具体来说，道路被离散化为单元，模型决定车辆何时从当前单元移动到下一个单元。由于其简单性，元胞自动机模型计算效率高，可以模拟大型路网上的大量车辆[KSSS04]然而，由于其离散性，生成的虚拟交通只能再现有限数量的真实交通行为。</p>
<p>相比之下，最早由Pipes [Pip53]和Reuschel [Reu50]引入的车辆跟驰模型，可以生成真实的驾驶行为和详细的车辆特征，但需要进行计算。他们假设交通流由分散的粒子组成[SZ14]，并对汽车间的相互作用进行了详细的建模。这些模型通过基于刺激-响应框架(Response = Sensitivity Stimulus)的连续时间微分方程来表示每辆车的位置和速度。</p>
<p>在过去的几十年里，大量的变化和扩展的汽车跟驰模型已经被用来建模主车对前车辆响应。两个著名的例子是最优速度模型(OVM) [BHN 95]和智能驾驶模型(IDM) [TH02]。<br>在OVM模型中，假设主车保持最优速度。它的加速度由它的速度和前车的最佳速度之差决定。在IDM模型中，根据车辆当前速度和相对于前车的速度和位置计算车辆的加减速。特定于车辆的参数使IDM模型能够模拟各种车辆类型和驾驶风格。</p>
<p>除了模拟单车道交通流外，还研究了多车道模拟[SN03, Dav04, THG05, HNT07]。<br>一个例子是改进的最优速度模型[Dav04]，该模型用于模拟双车道高速公路和有入口匝道的单车道高速公路上的交通;另一个例子是twolane交通模型[THG05]，用来模拟交通的横向效应。</p>
<p>为了生成详细的交通模拟，Shen和Jin [SJ12]提出了一种增强的IDM和连续换道技术。他们的技术可以产生具有平滑的加减速策略和灵活的车道悬挂行为的交通流。该模型对原有的IDM模型进行了修正，使其更适合于城市路网的信号处理。具体地，将加速度过程分为自由道路加速度项和减速项，自由道路加速度项描述了驾驶员达到期望速度的意愿，减速项描述了驾驶员与附近车辆保持安全距离的意愿。对减速项进行了修改，增加了一个激活控制部分，使被停车车辆的反应更加平稳。该模型将城市道路变道行为分为自由变道和强制变道两种情况，并为这两种情况提供了一个灵活的连续模型。</p>
<p>在相对自由的道路条件下，自由变道现象时有发生。这种行为是由k等[KTH07]的双车道MOBIL模型建模的。强制换道则应用于主车因为一些必要的因素要求换道行为,如到达车道终端或在十字路口转向,而主体辆及周边车辆之间的gap不支持自由换道(图5),陆等人(LCX 14)扩展完整的速度差异模型(FVDM) [JWZ01]以处理在农村交通仿真中的close-car-braking情况。后来，Lu等人在交通模拟中引入了人格模型[lwx14]</p>
<p>与单行道或多车道交通模拟相比，交叉口交通模拟难度更大。Doniec等人[DMPE08]提出了一种多智能体的交通模拟行为模型，将交叉口交通视为一个多智能体协调任务。具体来说，首先，每辆车感知周围的交通情况，做出决策;其次，提出了一种预测算法来模拟车辆的预测能力。Wang等[wxz18]在交通模拟中引入了影子交通的概念，以统一的方式对交通异常进行建模。Chao等人[CDJ15]设计了一个基于规则的流程来模拟混合交通模拟中车辆与行人的交互作用。</p>
<p>综上所述，微观交通模型的目的是描述特定的车辆行为，因此可以用来模拟连续车道和十字路口的交通。瓶颈通常是计算成本，特别是需要大规模模拟时间。</p>
<h5 id="混合方法"><a href="#混合方法" class="headerlink" title="混合方法"></a>混合方法</h5><p>Sewall等[SWL11]将这两种方法结合起来，提出了一种混合方法。他们的方法使用基于代理的模型来模拟感兴趣区域的交通，而其余区域使用连续体模型(见图6)。通过在两种建模方法之间动态和自动切换，他们的方法可以根据用户偏好来模拟不同详细级别下的交通。</p>
<p>细观模型是介于宏观方法和微观方法之间的一种中间方法。介观模型的核心思想是使用概率分布函数表示单个驾驶员行为的同时，以聚集的方式描述交通流动态[HB01c]。细观模型可分为三类:簇模型、车头时距分布模型和气体动力学模型。[FSS18]聚类模型通过描述车辆群来描述交通流的动态具有相同的属性[KMLK02,MKL05]。车头时距分布模型主要研究车头时距的统计特性。在介观方法中，最著名的模型是气体动力学模型，它将气体动力学与交通动力学进行类比。[PA60, THH99 HHST01, HB01a]。</p>
<p>在交通运输工程中，气体动力学模型通常不应用于仿真，但在推导其他连续体模型时仍保持其作用[Hel01]。例如，Hoogendoorn和Bovy [HB00, HB01b推导了一个基于气体动力学模型的多类多车道连续交通流模型。气体动力学模型也是许多宏观模型的基础，例如自适应巡航控制策略[DNP15]。<br>利用动力学理论推导出车辆交通的数学模型[FT13]，该模型放松了对车辆连续分布的空间位置和速度的假设。在计算机图形学中，由于存在大量的未知参数和复杂的微分或积分项，介观模型在交通仿真中很少被用到，这限制了仿真和动画的效率。</p>
<h4 id="路网生成"><a href="#路网生成" class="headerlink" title="路网生成"></a>路网生成</h4><p>交通仿真是车辆与路网相互作用的一种形式。底层道路网络的获取和建模是一个重要但具有挑战性的方面。真实世界道路网络的数字表示已经越来越有可用性，但这些数据往往不能直接用于模拟交通。基于宏观和微观建模方法的交通模拟是在由车道组成的道路网络上进行的。道路网络包含许多特性，如车道、十字路口、合并区域和坡道。对于道路网络的过程建模和几何表示，已经提出了许多方法</p>
<p>Parish等[PM06]提出了一个名为CityEngine[cit18]的软件，该系统采用基于L-system的过程方法来生成道路网络(图7(a))。以地图图像为输入，生成一组公路和街道，将土地分割成地块，并在相应的地块上为建筑物构建合适的几何形状。后来，许多研究者改进了基于CityEngine的路网生成模型[CEW 08, BN08, GPMG10]。例如，Sun等人[SYBG02]提出了一个基于模板的路网生成模型。具有更大的灵活性，用户可以直接使用Chen等人[CEW 08]的自动路网生成模型编辑路网。最近，Nishida等人[NGDA16]提出了一种交互式道路设计系统，该系统使用从示例道路网络中提取的补丁和统计信息。Hartmann等人[HWWK17]提出了一种基于实例的方法，利用生成对抗网络(GAN)来合成道路网络。他们使用二值图像来表示道路网络补丁,由于这些方法是为构建虚拟场景而设计的，因此它们常常无法为交通模拟提供必要的信息，如车道到车道的连接和邻接。</p>
<p>目前有几种用于交通仿真的道路建模技术。Yang和Koutsopoulos [YK96]使用node，link，segment和lane来描述道路网络的语义，他们的模型已被纳入交通模拟软件MITSIM [BAKY02]。在该模型中，segment表示具有相同几何线的lane集合，link表示segment集合，向量数据存储在segment的数据结构中，所存储的信息包括起始点/结束点和段弧的曲率，一个node用来描述一个交点，这里，node必须作为输入数据提供给模型，并且仅用于描述link是否连接，不考虑交叉口各方向link之间的冲突关系。在VISSIM [PTV11]交通模拟软件中，link和connector被用来描述道路网络的拓扑结构，这有助于描述具有更复杂几何形状的道路。然而，VISSIM的路网只由连续的路段组成，因此在交叉口处理不同方向的冲突是很困难的。类似地，其他道路网络表示模型[Par03, BC05, SWL11, SJ12]已经可用。最近，Cura等[CPP18]利用真实地理信息系统(real Geographic Information System, GIS)数据建立了一个包含拓扑交通信息、路面和街道对象的连贯的街道网络模型，该系统可以提供车道和车道间的相互连接，以作为交通仿真所需的基本几何信息，然而，他们使用lane作为原子单位来定义和组织道路网络，而忽略了道路网络的矢量数据。值得一提的是，为了方便不同驾驶模拟器之间的数据交换，目前提出了一种开放数据格式OpenDRIVE [DG06]来规范逻辑道路描述。</p>
<p>Wilkie等[WSL12]针对提高车辆运动的可视化，提出了一种新的道路网络模型图7(b))，将低细节的GIS数据自动转换为高细节的功能道路网络进行仿真。利用该模型可以生成区域中心拓扑结构和弧路表示。该模型以车道为基础定义交叉口，通过交通信号和预先确定的移动优先级，在模拟中对交叉路口进行管理，生成的道路网络库[WSLL15]可以在<a href="http://gamma.cs.unc.edu/RoadLib/上找到。该模型激发了更多基于车道的模拟技术，如Mao等[MWDW15]在Frenet框架下基于道路轴线的车道模型，以方便复杂的交通模拟。" target="_blank" rel="noopener">http://gamma.cs.unc.edu/RoadLib/上找到。该模型激发了更多基于车道的模拟技术，如Mao等[MWDW15]在Frenet框架下基于道路轴线的车道模型，以方便复杂的交通模拟。</a></p>
<p>有意义的是，根据不同的应用程序，不同细节级别的交通模拟需要不同的关于底层道路网络的信息。<br>一般情况下，宏观交通仿真对路网的细节要求较少，主要是需要几何信息，以便对交通流密度和速度的传播进行建模。相比之下，微观交通模拟由于输出单个车辆的详细运动，通常需要更多关于道路网络的信息。这些信息包括车道的分隔和连接、交通信号逻辑、在十字路口和坡道上移动优先级等。</p>
<h4 id="数据驱动的交通流仿真"><a href="#数据驱动的交通流仿真" class="headerlink" title="数据驱动的交通流仿真"></a>数据驱动的交通流仿真</h4><h5 id="真实数据收集"><a href="#真实数据收集" class="headerlink" title="真实数据收集"></a>真实数据收集</h5><p>交通传感器有几种形式[lbh10,Led08]。举几个例子，一个固定的传感器是感应环探测器，它通常被放置在高速公路和主要道路上，记录每辆经过的车辆的属性。另一个固定的传感器是摄像机，它也用于监控交通。除了固定的传感器，移动传感器也无处不在:手机和GPS设备被用来记录车辆的速度和位置</p>
<p>自20世纪60年代初引入感应环探测器以来，它已经成为使用最多的传感器[AKH 12, KMGK06]。<br>它可以检测通过或到达某一点的车辆。人行道上安装了绝缘的导电回路，在检测区域内通过或停车的车辆降低了回路的电感，然后，电子单元感知到频率的降低，并向控制器发送一个脉冲来表示车辆的通过或存在，这种道路传感器通常可以跟踪车辆的通过时间、车道id和速度。</p>
<p>摄像机也得到了广泛的应用。一个例子是下一代模拟(NGSIM)程序[NGS18]，在该程序中，摄像机安装在道路沿线，以每秒10帧的速度捕捉交通数据。结果数据集包含了详细的车辆轨迹。表1列出了四种流行的NGSIM数据集，包括道路长度、道路类型、记录时间和车辆数量。图8显示了在美国101高速公路上收集数据的一个例子:8个同步摄像机，安装在毗邻高速公路的36层建筑的顶部，记录通过研究区域的车辆。为了处理大量被捕获的数据，开发了NGSIMVIDEO [NGS18]来从图像中自动提取车辆轨迹</p>
<p>虽然通过道路传感器的传统的交通数据收集方法通常是昂贵的，当前，移动数据，如GPS报告扮演着越来越重要的角色，并已被用于估计全市交通状况[AA06, LNWL17]。出租车和拼车服务商如Uber和Lyft用这些设备装备他们的车队，汽车的位置、速度和方向等属性被发送到中央处理中心。<br>经过处理后，有价值的信息(例如交通状况和其他路线)将广播给道路上的司机[TEBH98]。目前公开的GPS数据集包括Mobile Century [HWH 10]、T-Drive [tdr10]、GeoLife [geo09]和Uber Movement[ube17]。GPS数据虽然很有用，但采样率较低且有噪声，这意味着两个连续的点之间的时间差可能很大(如大于60秒)，并且表现出时空稀疏性，这意味着数据在一定的时间段和区域内可能是稀缺的。因此，为了利用GPS数据重建交通动态，需要几个处理步骤[LNWL17, LJCL18]</p>
<p>除了单车数据外，许多研究还致力于收集联网车辆的交通数据[HL08,RMR14]。例如，2012年在美国密歇根州的安娜堡启动了安全试点模型部署SPMD计划。大约3000辆车辆装备了GPS天线和DSRC(专用短程通信)设备。每辆车都向附近的车辆和路边的单位广播基本的安全信息，包括它的位置和速度。由于这种类型的数据可以在高频率下采样(如10hz [BS15])，这可能会导致存储和通信系统的巨大成本，因此通常采用下采样但信息保存技术进行处理</p>
<h5 id="交通重建和合成"><a href="#交通重建和合成" class="headerlink" title="交通重建和合成"></a>交通重建和合成</h5><p>创建符合真实世界条件的交通的数字表征被称为虚拟交通，它是由Van Den Berg等人首先提出的。<br>在他们的工作中，利用交通传感器提供的时空数据重建和可视化一个连续的交通流。如图9所示，传感器(点A、点B、点C)每隔200-400米放置在道路上。对于某一辆车,传感器提供了一个元组$(tiA; liA viA;tiB;liB;viB;liC,liC;viC)$作为数据输入,分别为车辆通过时间t，车道id，车速v。任务是计算在给定车道上，在给定时间，以给定速度启动和到达车辆的轨迹(图9中的蓝色曲线)<br>该方法首先离散可能的状态-时间-空间，并约束车辆的运动到预先计算的路线图。然后，在路线图中为每辆车寻找最优轨迹，使换道次数和加减速度最小化，并与其他车辆的距离最大化，以获得平滑、真实的运动。对于多辆车，采用基于优先级的多机器人路径规划算法[VDBO07]来计算车辆的轨迹。然而，基于优先级的多智能体路由规划算法耗时较长，使得该方法随着搜索空间离散化分辨率的提高而变得难以处理。</p>
<p>Wilkie等人[WSL13]将稀疏传感器测量的宏观状态估计与基于agent的交通模拟系统相结合，引入了一种实时技术来重建单个车辆的真实运动。作为说明，在图10中，该方法具有一个交通状态估计阶段，在这个阶段，使用Kalman smoothers (EnKS) [Eve03]和一个连续交通模拟器来创建整个道路网络的速度和密度场的估计。然后利用状态估计来驱动一个基于agent的交通仿真模型，生成各个车辆的详细运动。最后，输出与传感器测量的原始交通信号相一致的二维交通流。与Sewall等[SVDBLM11]的交通重建工作相比，该方法具有更高的灵活性和更低的计算成本。然而，这种估计方法除了个别车辆的匹配外，基本上还是一种宏观模型。</p>
<p>Li等[LWL17]提出了一种利用GPS数据重建城市尺度交通的方法。为了解决数据覆盖不足的问题，该方法以GIS地图和GPS数据为输入，采用双阶段过程重构城市尺度的交通。在初始交通重建的第一阶段，利用统计学习与优化、地图匹配和行程时间估计技术相结合的方法，从稀疏的GPS数据中重建并逐步细化单个路段的交通条件。在动态数据补全的第二阶段，引入了基于元模型的仿真优化，以有效地细化第一阶段的重建结果，同时引入了一个微观仿真器，在数据覆盖不足的区域动态补全缺失的数据。为了保证重建的交通流是正确的，该方法考虑城市范围的边界和从第一阶段重建的交通流，进一步微调模拟。这是通过元模型的公式来计算交通流的误差近似值来实现的</p>
<p>上述交通重建技术主要用于预测同一场景下具有稀疏输入数据的完整交通流，而其他数据驱动的交通综合方法则旨在从有限的交通轨迹样本中生成新的交通流。Chao等人[CDR 18利用一组有限的车辆轨迹作为输入样本，通过纹理合/材质成和交通行为规则的融合来合成新的车辆轨迹。示例(输入)车辆轨迹集包含多种车道数和流密度的交通流段如图11所示，将交通流时空信息作为二维纹理，可以将新交通流的生成表示为纹理合成过程，通过最小化新开发的交通纹理能量度量有效地解决了这一问题。交通纹理中的每个texel在一定的帧内编码车辆的状态，包括车辆的速度、位置以及与相邻车辆的动态关系。交通纹理能量则度量合成的交通流与给定的交通流样本之间的相似性。通过在输入的交通流样本中寻找最匹配的texel来确定合成交通流中每辆车的速度。合成的输出不仅捕捉了时间和空间的动态输入交通流量，还保证了交通功能，如车辆之间的安全距离和换道规则。</p>
<p>另外一种方法是使用机器学习算法来学习车辆的详细运动特征，包括纵向加减速和换道过程。<br>Chao等人[CSJ13]提出了一种基于视频的方法，从交通动画视频中学习驾驶员的具体驾驶特性。<br>该方法将每辆车独特驾驶习惯的估计问题转化为寻找微观驾驶模型的最优参数集的问题，并采用自适应遗传算法求解。所学习的特征可用于再现给定视频中的交通流，具有较高的精度，也可应用于任何基于agent的交通仿真系统。Bi等[BMWD16]从车辆轨迹数据中学习变道特性。如图12所示，该方法首先从预先收集的车辆轨迹数据集中提取与换道任务最相关的特征。然后利用所提取的特征对换道决策过程进行建模，并对换道执行过程进行估计。</p>
<p>上述工作的重点是模拟高速公路或大型城市网络上的车辆。最近，Bi等[BMWD19]提出了一种基于深度学习的交叉口交通仿真框架。<br>为了描述车-环境相互作用的视觉感知效应，建立了一个称为网格地图的网格坐标系统，编码异源之间的车辆与行人混合的相互作用。如图13所示，五个通道的窗口在网格地图上滑动可以为每辆车生成一个环境矩阵。环境矩阵可以捕捉车辆和行人在车辆周围的速度和位置。除了环境矩阵外，基于收集的交叉口交通数据集的车辆标识还被用来描述当前车辆状态，然后利用卷积神经网络和递归神经网络对交叉口处的车辆轨迹模式进行学习。除了模拟路口交通，它还可以通过提供车辆新的目的地和驾驶环境来改变现有的路口交通动画。</p>
<h4 id="验证和评估"><a href="#验证和评估" class="headerlink" title="验证和评估"></a>验证和评估</h4><p>一般来说，可以执行两种类型的虚拟交通评估:可视方法和统计方法[TK04]在可视化验证中，将真实交通和模拟交通的图形表示并排显示，以确定它们是否可以区分[SVDBLM11, CSJ13]。Chao等[CDR 18的研究中，研究人员使用三种不同的方法(1)对生成的交通流进行成对比较，进行用户研究[KS40]。(2)提出了基于纹理的交通合成方法[CDR 18]，(3) IDM模型的最新发展之一。对于每个测试场景，分别使用上述三种不同的方法生成三个不同的交通流动画。如图14(a)所示，参与者被要求在两个动画剪辑中选择一个更真实的动画。如果参与者不能确定哪个剪辑在视觉上更吸引人，他们可以选择未决定的选项。为了平衡视觉刺激的顺序，成对的图案按照Williams design latin square [Wil49]进行展示。本用户研究的实验结果如图14(b)所示。除统计选票外，研究者还进行了单样本t检验和配对样本t检验，并计算出相应的p值来量化投票结果的统计意义。</p>
<p>主观的用户研究会耗费大量时间，且容易出错，因此通过定量和客观的度量进行统计验证不仅可以用来测量各种模拟交通流的真实性，还可以用来以一致的方式客观地比较不同交通模拟模型的性能。在交通模拟和动画技术中，由于交通的随机性，通常不进行直接的轨迹比较。对平均速度和流量随时间的比较是常见的(例如，Sewall等人的图15 [SWL11])。在更详细的级别，比如特定的运动参数，包括速度、加速度和车辆间隙也被用来验证交通模拟技术的有效性。</p>
<p>最近，Chao等[CDX 18]提出了一种通用的、基于字典的学习方法来定量和客观地测量交通轨迹数据的保真度。首先，从预先收集的地面真实交通数据中离线构建一个描述真实世界交通行为常见模式的交通模式字典。中间学习误差设置为基于字典的交通表示的基准，通过将基于字典的重建误差与基准字典误差进行比较，利用构建的字典对模拟交通流的真实性进行评估。如图17所示，该方法包括四个阶段:提取时空交通流特征;基于字典的任意输入交通流数据重建；基于重建误差的定量测度计算。该评价指标可以稳健地应用于任何模拟交通流。图16为几种不同交通数据的评价结果。保真度评分范围设置为0，10。如果模拟的交通更接近真实的训练交通数据集，那么逼真度评分的值就会更小，反之亦然。</p>
<h4 id="在自动驾驶中的应用"><a href="#在自动驾驶中的应用" class="headerlink" title="在自动驾驶中的应用"></a>在自动驾驶中的应用</h4><p>自动驾驶汽车有潜力将人们从驾驶汽车中解放出来，从而提高他们在旅途中的生产力，提高当前交通系统的安全性和效率，并将交通工具转变为任何人、任何时间都可以使用的公共设施。包括自动驾驶训练数据收集(第5.1节)，基于深度学习的运动规划方法(第5.1节)和自动驾驶的模拟(第5.3节)</p>
<h5 id="自动驾驶数据集"><a href="#自动驾驶数据集" class="headerlink" title="自动驾驶数据集"></a>自动驾驶数据集</h5><p>Jain等人[JKR 15]收集了10名驾驶员1180英里自然高速公路和城市驾驶行为的不同数据集。包括车内和车外的视频剪辑、GPS报告和速度测量数据。</p>
<p>comma.ai [SH16]数据集是一个公共数据集，它包含了大约7.25小时的高速公路行驶数据。数据集被分成11个视频剪辑。发布的视频分辨率为160320。包括速度，转向角度，GPS报告，陀螺仪，和IMU数据。</p>
<p>Berkeley DeepDrive视频数据集(BDDV) [GKB 16]由真实驾驶视频和GPS/IMU数据组成。多种驾驶研究人员记录了美国几个主要城市的城市、高速公路、城镇和农村地区的情况。BDDV包含超过10k小时的仪表盘-摄像机视频流。</p>
<p>LiDAR-Video数据集(LiVi-Set) [CWL 18]包括来自Velodyne激光扫描仪的大型高质量点云和来自仪表板相机的图像。维洛戴恩激光扫描仪收集点云360度水平视图和从-30.67到+10.67度垂直视图。<br>点云数据总量约为1TB。密度大约是每秒70万点。大约15G的视频片段是通过仪表盘摄像机录制的。<br>一个记录软件工具包被远程连接到车辆控制器，以便从车载传感器获取速度。该数据集涵盖了各种交通状况，包括主干道、主干道、山路、校区和特殊的旅游线路</p>
<p>本田研究所(Honda Research Institute)的驾驶数据集(HDD) [RCMS18]包括旧金山湾区104小时的驾驶数据。包括一组不同的交通场景。处理后的数据集的总大小约为150GB和104个视频小时</p>
<p>Drive360 [HDVG18]包括来自8个环绕视图摄像头的60小时驾驶视频。通过车辆CAN总线记录低水平驾驶动作如转向角度和速度控制。这些数据具有高时间分辨率、360度视角覆盖、帧同步和多种路况。</p>
<p>其他一些没有驾驶行为的数据集也有助于自动驾驶的视觉语义理解和基于视觉的控制。KITTI数据集[GLSU13, GLU12）是使用Foru高分辨率摄像机、Velodyne激光扫描仪和定位系统记录的。该数据集包括289对立体和光学流图像对，39.2km长度的立体视觉测程序列，以及在杂乱环境中捕获的超过200k的三维物体注释。该数据集用于立体视觉、光流、视觉测距/SLAM(同步定位和映射)和3D对象检测</p>
<p>城市景观数据集[COR 16]由一组记录在50个城市街道上的大型、多样的立体声视频序列组成。5000幅图像具有高质量的像素级注释;另外20,000张图片有粗糙的注释。数据集捕捉了不同季节的不同街景.</p>
<p>牛津RobotCar数据集[MPLN17]包含了超过1000公里的行驶数据，包括从6个摄像头收集的近2000万张图像，以及激光雷达和GPS数据，这些数据来自各种天气条件，包括大雨、夜间、阳光直射和降雪。<br>由于该数据集的记录时间跨度为一年，一些道路和建筑可能会发生变化。Udacity [Uda]的另一个数据集包括通过CAN总线进行的低水平驾驶操作.</p>
<p>基于视觉的城市环境语义分割是自动驾驶的基础。各种数据集已经被创建出来了[RSM 16,TKWU17,WU18]，包括各种各样的合成驱动或街道场景的语义分割，有助于语义理解和基于视觉的控制。不同自动驾驶数据集的详细比较如表2所示。</p>
<p>值得注意的是，自动驾驶数据集也可以用于交通模拟和动画。具体来说，首先，车辆轨迹可以用来校准交通仿真模型;二是大规模的交通数据集丰富了数据驱动的交通综合方法;第三，虚拟交通的评估可以受益于各种真实的交通数据集。</p>
<h5 id="运动规划与决策"><a href="#运动规划与决策" class="headerlink" title="运动规划与决策"></a>运动规划与决策</h5><p>运动规划和决策对于自动智能体在其环境中导航至关重要。这一节将回顾了几种基于学习的自动驾驶车辆和其他智能体的运动规划方法和决策算法。有兴趣的读者阅读更多的review文章，包括[KQCD15, PCY 16, SAMR18]</p>
<p>Pomerleau[Pom89]介绍了ALVINN神经网络中的自动驾驶陆地车辆，它开创了自动驾驶导航的端到端方法。ALVINN将摄像机和激光测距仪拍摄的图像作为导航车辆的输入。Chen等人[CSKX15]没有采用决策驱动的中介感知（mediated perception）和回归方法的行为反射，而是用基于图像的直接感知映射了驾驶的几种可见/可解释的行为。</p>
<p>端到端自动驾驶深度学习框架也发展了很多。Bojarski等[BDTD 16]使用CNN(称为PilotNet [BYC 17])从前置摄像头获取原始像素作为输入来产生转向行为。该框架对于不需要人工分解和语义抽象的道路跟踪非常强大。Gurghian等人[GKB 16]提出了一种end-to-end deep CNN来直接估计车辆的车道位置，输入图像来自侧面安装的下面对摄像头，这提供了一个比前面的摄像头更优化的视角进行车道标记。</p>
<p>后来，Xu等[XGYD17]使用基于大规模众源车辆动作数据的FCN-LSTM框架来学习通用的车辆运动。<br>这种方法采用了一种新的范式，从未经校准的来源学习模型。经过训练后，它可以产生离散的动作如直行、停车、左转弯、右转弯，也可以产生连续的动作如车道跟踪和转向控制用于自动驾驶车辆的导航。</p>
<p>Lenz等[LDLK17]研究了高速公路入口处的车辆运动。他们训练了一个深度神经网络，利用部分可观测的马尔科夫决策过程(POMDPs)来预测车辆的运动。Kuefler等[KMWK17]采用生成式对抗模仿学习(GAIL)学习驾驶行为，该方法克服了级联误差的问题，能够产生真实的驾驶行为。Hecker等人[HDVG18]将周围360度视角摄像头的信息整合到路线规划器中。该方法中使用的网络将传感器输出直接映射到低水平驾驶动作，包括转向角和速度。Kim等人[KRD 18]引入了一种端到端的、可解释的自动驾驶方法，该方法结合了一个基于内省的解释模型。该模型由两部分组成:第一部分是基于cnn的视觉注意力机制，将图像映射到驾驶行为;第二部分是基于注意力的视频-文本模型，用于对模型动作进行文本解释。Yang等人[YLWX18]利用在CARLA和TORCS中收集的虚拟交通数据来预测车辆行为，即DU-drive(图18)。</p>
<p>近年来，强化学习也被应用于自动驾驶。Abbeel等人[ADNT08]提出了一种有效的算法来协调全局导航和生成车辆轨迹的局部规划之间的权衡。Silver等人[SBS13]提出了一种适合自动导航系统的耦合成本函数，以平衡不同的偏好，包括车辆应该在哪里以及如何驾驶。Lillicrap等人[LHP 15]采用深度q-learning实现无模型系统，该系统在模拟驾驶环境中学习引导车辆保持在赛道上的策略。Kuderer等人[KGB15]提出了一种基于特征的反强化学习(IRL)方法来学习自动驾驶的个体驾驶风格。Wolf等人[WHW 17]提出了一种深度Q-Networks (Deep Q-Networks, DQN)，用于在三维物理仿真中引导车辆。在这种方法中，车辆的目标是沿着车道完成任意路线上的圈数，而基于动作的奖励功能是由真实的强化学习场景中中激活的。Pan等人[PYWL17]利用新型的现实翻译网络(VISRI)在虚拟环境中训练自动驾驶模型，并将其应用于现实环境中。在该虚拟-真实增强学习框架中，首先将虚拟环境中的图像分割为场景解析表示，然后将其转换为合成图像。Liang等[LWYX18]提出了一种通用的可控模仿强化学习(CIRL)方法来缓解大连续动作空间的低探索效率，基于直接从CARLA模拟器输入的视觉信息。</p>
<p>为了在复杂的交通环境中高效、安全地驾驶车辆，自动驾驶汽车需要对周围车辆的运动进行预测。车辆与行人之间的相互作用要准确表达[LVL14]。轨迹预测的任务可以分为几个类别:基于物理、基于机动策略和基于交互的模型。此外，大量基于深度学习的人类轨迹预测工作已经完成[AGR 16, VMO18, GJFF 18, MA18, SKS 19, XPG18, HST 18]。在这里，我们将重点限制在使用深度神经网络进行车辆轨迹预测</p>
<p>Lee等人[LCV 17]提出了一种深层随机IOC RNN编解码器框架DESIRE，用于预测动态场景中交代理未来的距离，可以生成准确的车辆行驶轨迹。Kim等人[KKK 17]提出了一种基于lstm的概率车辆轨迹预测方法，该方法使用占用网格图来表征驾驶环境。Deo和Trivedi[DT18]采用卷积社会池网络来预测高速公路上的车辆轨迹，整个网络包括LSTM编码器、卷积社会池层和基于操作的解码器。具体来说，它首先使用LSTM编码器来学习车辆动力学基于跟踪历史，然后，使用卷积社会池层捕获所有车辆轨迹的相互依赖关系，最后训练一个基于机动的LSTM解码器来预测未来车辆轨迹的分布</p>
<h5 id="自动驾驶仿真"><a href="#自动驾驶仿真" class="headerlink" title="自动驾驶仿真"></a>自动驾驶仿真</h5><p>现实世界的数据量还不足以覆盖许多复杂的交通场景,从而制约自动驾驶系统学习不同的驾驶策略,更重要的是,无人驾驶汽车出于安全考虑，总是采取最保守、最低效的决策。据报道，自动驾驶汽车造成了一些致命的事故。这些结果都刺激了高保真驾驶模拟器的发展，其作为一种替代和有效的工具，可以为训练自动驾驶车辆提供各种类型的交通条件。此外，一个模拟器可以在自动驾驶车辆部署到现实世界之前进行全面彻底的安全测试[ARB 15, APPI11, LF09]</p>
<p>事实上，从自动驾驶研究的早期开始，仿真就被用于训练驾驶模型[Pom89]。<br>后来，赛车模拟器被用来评估各种驾驶方法。例如，Chen等[CSKX15]使用TORCS [WEG 00]来评价提出的自动驾驶的直接感知模型。最近，研究人员[RVRK16]利用侠盗猎车手GTAV来推导自动驾驶策略，也获得了与借助手动注释的真实世界图像产生的控制策略相媲美的性能。</p>
<p>CARLA [DRC 17]是一个开源的模拟器，用于支持城市自动驾驶模型的开发、培训和验证。该仿真平台支持传感器套件的灵活设置，并提供可用于训练驾驶策略的数据。这些数据包括GPS坐标、速度、加速/减速和碰撞的等。可以指定范围广泛的环境因素，包括天气和一天中的时间(图19)。通过这些设置，CARLA已经被用于研究许多自动驾驶方法的性能，包括经典的模块化方法、通过模仿学习的端到端训练模型，以及通过强化学习的端到端训练模型。</p>
<p>Best等[BNP 18]提出了一种用于自动驾驶数据生成和驾驶策略测试的高保真仿真平台autonova-sim。autonova-sim是一组高级可扩展模块。与CARLA类似，它还支持车辆传感器系统的特定配置、时间和天气条件的变化，以及非车辆参与者(如骑自行车者和行人)在交通中的移动。</p>
<p>此外，最近的几个项目试图建立仿真平台来训练端到端驾驶系统，并为自动驾驶测试提供丰富的虚拟交通场景。一个例子是Apollo [apo18]，它整合了大量来自实际交通和虚拟交通的驾驶数据。阿波罗的目标是为自动驾驶系统的开发创造一个强大的虚拟闭环:从算法到评估，再到更新算法。Apollo的一个局限性是，虚拟交通数据是用特定的、定义明确的障碍物和交通信号手动创建的，与真实的交通状况相比，这些数据的真实性和复杂性不高。</p>
<p>最近，Li等人[LPZ19]开发了一个仿真框架AADS，它可以用模拟的交通流增强真实图像，从而生成具有真实感的图像。<br>利用激光雷达和摄像机的数据，该框架可以根据车辆的实际行驶轨迹，将模拟的交通流合成到背景中。复合图像可以被修改为不同的视点，并进行充分的注释，可以用于自动驾驶系统的开发和测试。<br>该框架旨在克服人工开发虚拟环境的成本较高和使用虚拟图像训练自动驾驶时可能的车辆性能下降问题。</p>
<p>Li等人[LWL19]开发的另一个框架ADAPS从事故中获取相关自动驾驶数据。该框架由两个仿真平台组成。第一个仿真平台以3D方式运行，用于测试所学习的策略和模拟事故;第二个仿真平台运行在2D中，用于分析第一个仿真平台中发生的事故，并通过提供备用安全轨迹来解决事故。然后根据安全轨迹生成大量带注释的数据，用于训练和更新控制策略。与以前的技术(如DAGGER [RGB11])相比，ADAPS还代表了一种更有效的在线学习机制，可以极大地减少生成健壮控制策略所需的迭代次数。</p>
<h4 id="讨论"><a href="#讨论" class="headerlink" title="讨论"></a>讨论</h4><p>首先，交通仿真模型应该能够对尽可能多的复杂交通行为进行建模，同时保持计算效率。然而，对于现有的微观交通模型，车辆的每一个行为，如加速/减速和换道，都是单独建模和控制的。此外，微观交通模型更多地关注车辆在前进方向上的运动，这在某种程度上是有限的，换道行为和车辆横向运动一般被忽略。此外，根据车辆跟驰规律，车辆的运动主要受前车的影响，因此得到的仿真结果很少涉及视场中其他车辆的加减速计算。为了模拟更真实的交通流，需要开发一个统一的、可扩展的仿真框架，用于丰富的车辆行为，包括加速/减速、停留在车道内、变道以及与非车辆交通参与者(如行人和骑自行车者)的交互</p>
<p>其次，尽管有许多成功的演示，目前的数据驱动的交通动画方法不能处理车辆和其他移动对象(例如行人)之间的交互。其中一个主要原因是同时获取车辆、行人和环境因素的大尺度时空数据是一项艰巨的任务。在交通重建中，通常将道路内传感器和GPS数据作为两类交通数据分别进行计算。同时，现有的数据限制了交通重建的准确性。因此，结合各种数据源，如道路传感器、视频流和GPS跟踪，有可能提高重建精度。</p>
<p>第三，对于虚拟交通保真度的评估，基于字典的度量[CDX 18]提供了一个可行的解决方案。然而，作为数据驱动方法的一个常见问题，交通数据的质量和组成对生成的字典有直接和实质性的影响，从而影响评价结果。此外，该框架提取出每辆车的加速度、速度、相对速度和与前车的间隙距离来描述车辆的瞬时状态，为了更好地捕获交通模式进行字典学习，还应该考虑和提取交通流的更多特征，包括车辆运动学约束、道路约束和驾驶员特征。对于宏观的交通模拟，有必要开发保真度指标，以一种聚集的方式测量交通流，包括流密度和速度</p>
<p>最后，对于自动驾驶来说，解决自动驾驶车辆和其他道路使用者之间的交互仍然是一个挑战。现有的仿真器较少考虑双方的相互作用。举例来说，在Apollo仿真平台[apo18]和[BNP 18]的工作中，都实现了两种类型的非车辆交通参与者:行人和骑自行车的人。然而，这些非车辆代理的行为是预先定义的，因此它们不能实时地对车辆做出反应。虽然在CARLA [DRC 17]中引入了动态行人，但是车辆与行人之间的交互是以一种简单的预先指定的方式进行处理:行人在移动之前会查看附近是否有车辆，然后在没有进一步检查的情况下继续移动，这种交互模式还过于简单，需要再深入研究。</p>

      
    </div>
    
    
    

    

    

    
      <div>
        <ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    鲨鱼观海
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://iamwxy.com/交通流仿真总结.html" title="交通流仿真总结">http://iamwxy.com/交通流仿真总结.html</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>
    本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！
  </li>
</ul>

      </div>
    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/自动驾驶/" rel="tag"># 自动驾驶</a>
          
            <a href="/tags/自动驾驶仿真/" rel="tag"># 自动驾驶仿真</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/待写文章.html" rel="next" title="待写文章">
                <i class="fa fa-chevron-left"></i> 待写文章
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/交通流仿真建模-意义和主要工作.html" rel="prev" title="交通流仿真建模 | 意义和主要工作">
                交通流仿真建模 | 意义和主要工作 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.jpg"
                alt="鲨鱼观海" />
            
              <p class="site-author-name" itemprop="name">鲨鱼观海</p>
              <p class="site-description motion-element" itemprop="description">生活随笔 高效学习 自动驾驶 数据分析 交叉领域 读书笔记 Coder&Engineer</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">160</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-4"><a class="nav-link" href="#基于模型的交通流建模"><span class="nav-number">1.</span> <span class="nav-text">基于模型的交通流建模</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#宏观方法"><span class="nav-number">1.1.</span> <span class="nav-text">宏观方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#微观方法"><span class="nav-number">1.2.</span> <span class="nav-text">微观方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#混合方法"><span class="nav-number">1.3.</span> <span class="nav-text">混合方法</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#路网生成"><span class="nav-number">2.</span> <span class="nav-text">路网生成</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#数据驱动的交通流仿真"><span class="nav-number">3.</span> <span class="nav-text">数据驱动的交通流仿真</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#真实数据收集"><span class="nav-number">3.1.</span> <span class="nav-text">真实数据收集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#交通重建和合成"><span class="nav-number">3.2.</span> <span class="nav-text">交通重建和合成</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#验证和评估"><span class="nav-number">4.</span> <span class="nav-text">验证和评估</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#在自动驾驶中的应用"><span class="nav-number">5.</span> <span class="nav-text">在自动驾驶中的应用</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#自动驾驶数据集"><span class="nav-number">5.1.</span> <span class="nav-text">自动驾驶数据集</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#运动规划与决策"><span class="nav-number">5.2.</span> <span class="nav-text">运动规划与决策</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#自动驾驶仿真"><span class="nav-number">5.3.</span> <span class="nav-text">自动驾驶仿真</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#讨论"><span class="nav-number">6.</span> <span class="nav-text">讨论</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">鲨鱼观海</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
      <span class="post-meta-item-text">Site words total count&#58;</span>
    
    <span title="Site words total count">273.4k </span>
  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>




  <span class="post-meta-divider">|</span>



  <div class="theme-info">
  <span> <a href="http://www.beian.miit.gov.cn/" style="font-weight: bold">豫ICP备19024762号</a></span>
  </div>







        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
          <span id="scrollpercent"><span>0</span>%</span>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  


  

  

</body>
</html>
